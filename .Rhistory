View(Auto)
head(Auto)
head(Auto, 20)
dim(Auto)
View(Auto)
names(Auto)
plot(Auto$mpg, Auto$cylinders)
attach(Auto)
View(Auto$mpg)
attach(Auto)
plot(cylinders, mpg)
cylinders <- as.factor(cylinders)
plot(cylinders, mpg)
plot(cylinders, mpg, col = 'red', varwidth = T)
hist(Auto, col = 2, breaks = 15)
hist(mpg, col = 2, breaks = 15)
pairs(Auto)
pair()
pairs()
~ mpg + displacement + horsepower + weight + aceleration, data = Auto
pairs(
~ mpg + displacement + horsepower + weight + aceleration,
data = Auto
)
pairs(
~ mpg + displacement + horsepower + weight + acceleration,
data = Auto
)
plot(horsepower, mpg)
attach(Auto)
plot(horsepower, mpg)
identity(horsepower, mpg)
identity(horsepower, mpg, name)
identity(horsepower, mpg, name)
names(Auto)
plot(horsepower, mpg)
identity(horsepower, mpg, name)
Auto <- read.table("Auto.data", header =T, na.strings = "?", stringsAsFactors = T)
attach(Auto)
plot(horsepower, mpg)
identity(horsepower, mpg, name)
Auto <- read.table("Auto.data", header =T, na.strings = "?", stringsAsFactors = T)
attach(Auto)
plot(horsepower, mpg)
identity(horsepower, mpg, name)
identity(horsepower, mpg, labels = name)
identity(Auto$horsepower, Auto$mpg, labels = Auto$name)
plot(horsepower, mpg)
# Crie um conjunto de dados de exemplo
dados <- data.frame(
Carro = c("Carro1", "Carro2", "Carro3", "Carro4", "Carro5"),
Horsepower = c(150, 200, 120, 180, 210),
MPG = c(20, 18, 25, 22, 17)
)
# Crie um gráfico de dispersão (scatter plot) de Horsepower vs. MPG
plot(dados$Horsepower, dados$MPG, pch = 19, xlim = c(0, 250), ylim = c(0, 30), xlab = "Horsepower", ylab = "MPG")
# Use a função identify para identificar pontos no gráfico
identify(dados$Horsepower, dados$MPG, labels = dados$Carro, n = 1)
# Após rodar esse código, o gráfico será exibido, e você poderá clicar com o mouse em pontos no gráfico para identificá-los.
# Quando você clicar em um ponto, o rótulo do carro correspondente será exibido.
# Crie um conjunto de dados de exemplo
dados <- data.frame(
Carro = c("Carro1", "Carro2", "Carro3", "Carro4", "Carro5"),
Horsepower = c(150, 200, 120, 180, 210),
MPG = c(20, 18, 25, 22, 17)
)
# Crie um gráfico de dispersão (scatter plot) de Horsepower vs. MPG
plot(dados$Horsepower, dados$MPG, pch = 19, xlim = c(0, 250), ylim = c(0, 30), xlab = "Horsepower", ylab = "MPG")
# Use a função identify para identificar pontos no gráfico
identify(dados$Horsepower, dados$MPG, labels = dados$Carro, n = 1)
# Após rodar esse código, o gráfico será exibido, e você poderá clicar com o mouse em pontos no gráfico para identificá-los.
# Quando você clicar em um ponto, o rótulo do carro correspondente será exibido.
identity(Auto$horsepower, Auto$mpg, labels = Auto$name, n = 1)
names(Auto)
identity(horsepower, mpg, labels = name, n = 1)
Auto <- read.table("Auto.data", header =T, na.strings = "?", stringsAsFactors = T)
attach(Auto)
plot(horsepower, mpg)
identity(horsepower, mpg, labels = name, n = 1)
identity(horsepower, mpg, labels = name)
identity(horsepower, mpg, name,)
identity(horsepower, mpg, name)
identity(horsepower, mpg)
Auto <- read.table("Auto.data", header =T, na.strings = "?", stringsAsFactors = T)
attach(Auto)
plot(horsepower, mpg)
identify(horsepower, mpg, name)
summary(Auto)
summary(mpg)
summary(name)
# CONCEPTUAL ----
## 1 ----
### Os p-values referente à TV e rádio - table 3.4 - são relevantes <0.0001
### Portanto, a hipotse nula, para ambos, pode ser rejeitada. Visto que, a tabela
### mostra forte verossimilhança entre comerciais de TV/radio e o aumento nas
### vendas.
### Por outro lado, o p-value de jornal é insignificante 0.8599. Dessa forma, deve-se
### adotar a hipótese nula para jornal. Pois, propaganda através desse veículo de
### informação não impacta as vendas positivamente na presença dos demais.
## 2 ----
### As duas abordagens KNN-classifier e KNN - regression funcionam a partir da
### mesma ideia básica: encontrar os vizinhos mais próximos na quantidade definida por K.
### A partir disso, o classifier irá atribuir o novo valor à uma classe que tenha
### a maior probabilidade de pertencer. E, o regression irá prever o valor a partir
### dos vizinhos mais próximos.
## 3 ----
### a ----
#### Y = b0 + b1.GPA + b2.IQ + b3.Level + b4.GPA:IQ + b5.GPA:Level
#### Opção para college (1): Y = 50 + 20.GPA + 0.07.IQ + 35.1 + 0.01.GPA:IQ + -10.GPA:1
####                         y = 85 + 20GPA + 0,07IQ + 0.01GPA:IQ + (-10GPA:1)
#### Opção   highschool (0): y = 50 + 20.GPA + 0.07IQ + 35.0 + 0.01.GPA:IQ + (-10.GPA:0)
####                         y = 50 + 20GPA + 0,07IQ + 0.01GPA:IQ
#### Diferença entre College salary e Hifgschool salary
####       85 + 20GPA + 0.07IQ + 0.01GPA.IQ - 10GPA
#### (-1) -50 - 20GPA - 0.07IQ - 0.01GPA.IQ
####      =35 - 10GPA
#### Se diferença >= 0
#### 35 - 10GPA >= 0 --> GPA <= 3,5
#### Se diferença <= 0
#### 35 - 10GPA <= 0 --> GPA >= 3,5
#### Depende do valor do GPA para obter a resposta
#### Portanto, o item iii é a resposta correta.
### b ----
#### 85 + 20*4 + 0,07*110 + 0.01*4*110 + (-10*4*1)
sallary <- 85 + 20*4 + 0.07*110 + 0.01*4*110 + (-10*4*1)
cat("Para uma pessoa que possua college, gpa=4 e iq=110 o salário será:",sallary,"mil dólares")
### c ----
#### Falso: apenas o coeficiente não pode ser usado como evidência de significância estatística
## 4 ----
### a ----
#### Aparentemente não há informação suficiente para responder essa questão.
#### Porém, como a questão cita que a relação entre X e Y é linear, é possível
#### que a relação linear obtenha RSS menores do que a cúbica.
### b ----
#### Aparentemente não há informação suficiente para responder essa questão.
#### Porém, é possível supor que a regressão polinomial implicará em maior RSS
#### devido ao fato de haver possibilidade de overfitting no treino e o erro
#### ser maior que o da regressão linear.
### c ----
#### Provavelmente o RSS para o modelo polinomial seja menor, devido sua maior
#### flexibilidade quando comparado com o modelo linear.
### d ----
#### Não é possível saber quão longe o modelo está da linearidade. Portanto, fica
#### a dúvida referente ao menor RSS. Visto que, se o modelo estiver mais próximo
#### da linearidade o menor RSS tende a ser o da regressão linear. Assim como, se
#### for o contrário é possível esperar melhor resultado do RSS para o modelo
#### polinomial.
## 5,6,7 ----
#### Não resolvi essas questões. Há um link com as soluções: https://rpubs.com/ppaquay/65559
## 8 ----
lm_mpg_horsepower <- lm(mpg ~ horsepower, data = Auto)
summary(lm_mpg_horsepower)
### a.i ----
#### O teste F estar distante do número 1, é evidência de que a h0 pode ser
#### descartada em favor do modelo. Bem como o fato do p-value ser pratica-
#### mente 0, fortalece o abandono da h0 em favor do modelo.
#### Portanto, com o valor do teste F distante de 1 e o p-value baixo, é pos-
#### sível concluir que há grande significância estatística entre MPG e HP.
### a.ii ----
#### A porcentagem de erro se dá pelo seguinte cálculo
mean(Auto$mpg)
rse_mpg_horsepower <- 4.906
pctgm_erro <- (rse_mpg_horsepower/mean(Auto$mpg))*100
#### Portanto, a porcentagem de erro do modelo em questão é de 20.92%. Ainda,
#### o R-squared vale 0.6059, isso mostra que 60.59% da variabilidade é expli-
#### cada pelo modelo.
### a.iii ----
#### Correlação negativa. Visto que a estimativa para horsepower é -0.157845
### a.iv ----
predict(lm_mpg_horsepower, data.frame(horsepower=c(98)), interval = 'confidence')
predict(lm_mpg_horsepower, data.frame(horsepower=c(98)), interval = 'prediction')
#### A previsão é um consumo de 24.46 mpg para horsepower = 98.
#### Intervalo de confiança (95%) de 23.97 até 24.96
#### Intervalo de previsão 14.80 até 34.12
### b ----
plot(Auto$horsepower, Auto$mpg)
abline(lm_mpg_horsepower, col = 'orange4')
### c ----
par(mfrow=c(2,2))
plot(lm_mpg_horsepower)
#### Baseado no formato de U do gráfico residuals vs fitted, é possível identi-
#### ficar algum tipo de não linearidade.
#### Baseado no formato de U do gráfico residuals vs fitted, é possível identi-
#### ficar algum tipo de não linearidade.
## 9 ----
### a ----
pairs(Auto)
plot(Auto)
### b ----
?cor
colnames(Auto)
cor(Auto[, -9])
#### Função cor() sem a variável name(-9)
cor(Auto[, c('horsepower', -9])
#### Função cor() sem a variável name(-9)
cor(Auto[, c('horsepower', -9)])
#### Função cor() sem a variável name(-9)
cor(Auto[, c(-4, -9)])
cor(Auto[,-'horsepower'])
cor(Auto[,'horsepower'])
#### Função cor() sem a variável name(-9)
cor(Auto[, c(-4, -9)])
?as.factor
#### Função cor() sem a variável name(-9)
cor(as.factor(Auto[, c(-9)]))
#### Função cor() sem a variável name(-9)
cor(Auto[, c(-9)])
#### Função cor() sem a variável name(-9)
as.factor(Auto$horsepower)
cor(Auto[, c(-9)])
#### Função cor() sem a variável name(-9)
Auto$horsepower <- as.factor(Auto$horsepower)
cor(Auto[, c(-9)])
cor(Auto[,c(-9)])
cor(Auto[,-9])
cor(Auto[ ,-9])
#### Função cor() sem a variável name(-9)
Auto$horsepower <- as.numeric(Auto$horsepower)
cor(Auto[ ,-9])
#### Função cor() sem a variável name(-9)
rm(list = ls())
cor(Auto[ ,-9])
library(ISLR2)
summary(Auto)
cor(Auto[ ,-9])
subset_Auto <- Auto[,-9]
#### Função cor() sem a variável name(-9)
cor(subset_Auto)
### c ----
lm(mpg ~ . , data = subset_Auto)
### c ----
lm_mpg_todos <- lm(mpg ~ . , data = subset_Auto)
summary(lm_mpg_todos)
###c.i ----
#### Visto que: F-statistic: 252.4 e p-value: < 2.2e-16. Então, é possível
#### concluir que há significância estatística entre os preditores e a resposta
### c.ii ----
#### Os preditores com p-values mais baixos são: Weight, year, origin e displacement
### c.iii ----
#### Sugere correlação positiva com a resposta (MPG). A cada unidade de aumento em
#### year o mpg também aumenta 0.75. Isso mostra que com o passar dos anos os
#### carros passaram a percorrer mais distâncias com 1 gallon.
### d ----
plot(lm_mpg_todos)
plot(predict(lm_mpg_todos), rstudent(lm_mpg_todos))
###c.i ----
#### Visto que: F-statistic: 252.4 e p-value: < 2.2e-16. Então, é possível
#### concluir que há significância estatística entre os preditores e a resposta
### c.ii ----
#### Os preditores com p-values mais baixos são: Weight, year, origin e displacement
### c.iii ----
#### Sugere correlação positiva com a resposta (MPG). A cada unidade de aumento em
#### year o mpg também aumenta 0.75. Isso mostra que com o passar dos anos os
#### carros passaram a percorrer mais distâncias com 1 gallon.
### d ----
plot(lm_mpg_todos)
###c.i ----
#### Visto que: F-statistic: 252.4 e p-value: < 2.2e-16. Então, é possível
#### concluir que há significância estatística entre os preditores e a resposta
### c.ii ----
#### Os preditores com p-values mais baixos são: Weight, year, origin e displacement
### c.iii ----
#### Sugere correlação positiva com a resposta (MPG). A cada unidade de aumento em
#### year o mpg também aumenta 0.75. Isso mostra que com o passar dos anos os
#### carros passaram a percorrer mais distâncias com 1 gallon.
### d ----
plot(lm_mpg_todos)
###c.i ----
#### Visto que: F-statistic: 252.4 e p-value: < 2.2e-16. Então, é possível
#### concluir que há significância estatística entre os preditores e a resposta
### c.ii ----
#### Os preditores com p-values mais baixos são: Weight, year, origin e displacement
### c.iii ----
#### Sugere correlação positiva com a resposta (MPG). A cada unidade de aumento em
#### year o mpg também aumenta 0.75. Isso mostra que com o passar dos anos os
#### carros passaram a percorrer mais distâncias com 1 gallon.
### d ----
plot(lm_mpg_todos)
#### Limpar o ambiente de trabalho
rm(list = ls())
#### Carregar biblioteca
library(ISLR2)
#### Encontrar a posição da variável qualitativa
colnames(Auto)
#### subset sem a variável name
subset_Auto <- Auto[,-9]
#### Função cor() sem a variável name(-9)
cor(subset_Auto)
### c ----
lm_mpg_todos <- lm(mpg ~ . , data = subset_Auto)
summary(lm_mpg_todos)
###c.i ----
#### Visto que: F-statistic: 252.4 e p-value: < 2.2e-16. Então, é possível
#### concluir que há significância estatística entre os preditores e a resposta
### c.ii ----
#### Os preditores com p-values mais baixos são: Weight, year, origin e displacement
### c.iii ----
#### Sugere correlação positiva com a resposta (MPG). A cada unidade de aumento em
#### year o mpg também aumenta 0.75. Isso mostra que com o passar dos anos os
#### carros passaram a percorrer mais distâncias com 1 gallon.
### d ----
plot(lm_mpg_todos)
###c.i ----
#### Visto que: F-statistic: 252.4 e p-value: < 2.2e-16. Então, é possível
#### concluir que há significância estatística entre os preditores e a resposta
### c.ii ----
#### Os preditores com p-values mais baixos são: Weight, year, origin e displacement
### c.iii ----
#### Sugere correlação positiva com a resposta (MPG). A cada unidade de aumento em
#### year o mpg também aumenta 0.75. Isso mostra que com o passar dos anos os
#### carros passaram a percorrer mais distâncias com 1 gallon.
### d ----
par(mfrow=c(2,2))
plot(lm_mpg_todos)
#### No q-q gráfico é possível observar tendência de linearidade até o ponto 2.
#### Já no residuals vs fitted values é possível observar leve tendência de
#### não linearidade.
plot(predict(lm_mpg_todos), rstudent(lm_mpg_todos))
#### No q-q gráfico é possível observar tendência de linearidade até o ponto 2.
#### Já no residuals vs fitted values é possível observar leve tendência de
#### não linearidade.
par(mfrow=c(1,1))
plot(predict(lm_mpg_todos), rstudent(lm_mpg_todos))
colnames(Auto)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ acceleration + horsepower.weight, data = Auto)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ acceleration + horsepower*weight, data = Auto)
summary(lm_mpg_interaction_1)
summary(lm_mpg_todos)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ horsepower*weight, data = Auto)
summary(lm_mpg_interaction_1)
summary(lm_mpg_todos)
summary(lm_mpg_interaction_1)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ year + horsepower*weight, data = Auto)
summary(lm_mpg_interaction_1)
summary(lm_mpg_todos)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ year + origin + horsepower*weight, data = Auto)
summary(lm_mpg_interaction_1)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ year + horsepower*weight, data = Auto)
summary(lm_mpg_interaction_1)
lm_mpg_interaction_2 <- lm(mpg ~ year + origin + horsepower*weight, data = Auto)
summary(lm_mpg_interaction_2)
summary(lm_mpg_todos)
m_mpg_interaction_3 <- lm(mpg ~ year + origin + displacement*weight, data = Auto)
summary(lm_mpg_interaction_3)
lm_mpg_interaction_3 <- lm(mpg ~ year + origin + displacement*weight, data = Auto)
summary(lm_mpg_interaction_3)
lm_mpg_interaction_3 <- lm(mpg ~ year + origin + displacement + horsepower*weight, data = Auto)
summary(lm_mpg_interaction_3)
summary(lm_mpg_interaction_2)
summary(lm_mpg_interaction_1)
summary(lm_mpg_interaction_2)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ year + horsepower*weight, data = subset_Auto)
summary(lm_mpg_interaction_1)
lm_mpg_interaction_2 <- lm(mpg ~ year + origin + horsepower*weight, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ . + horsepower*weight, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ . + horsepower:weight, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ . + horsepower*weight + year:origin, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ . + horsepower*weight + year:cylinders, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ . + displacement*weight + year:cylinders, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ . + horsepower*weight + year:cylinders, data = subset_Auto)
summary(lm_mpg_interaction_2)
?lm
lm_mpg_interaction_2 <- lm(mpg ~ .-displacement - acceleration + horsepower*weight + year:cylinders, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm(formula = mpg ~ . - name + displacement * weight + year:cylinders, Auto)
ajuste_alvo <- lm(formula = mpg ~ . - name + displacement * weight + year:cylinders, Auto)
summary(ajuste_alvo)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ .
-displacement
- acceleration
- origin
+ horsepower*weight + year:cylinders, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ .
-displacement
- acceleration
+ horsepower:weight + year:cylinders, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ .
-displacement
- acceleration
- year
+ horsepower:weight + year:cylinders, data = subset_Auto)
summary(lm_mpg_interaction_2)
lm_mpg_interaction_2 <- lm(mpg ~ .
-displacement
- acceleration
+ horsepower:weight
+ year:cylinders,
data = subset_Auto)
summary(lm_mpg_interaction_2)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ year + horsepower:weight, data = subset_Auto)
summary(lm_mpg_interaction_1)
#### Utilizando o gráfico studentized vs predict é possível verificar que alguns
#### pontos se afastam mais que os demais do valor 0, mostrando que é possível
#### que haja high leverage entre os preditores.
### e ----
lm_mpg_interaction_1 <- lm(mpg ~ year + horsepower*weight, data = subset_Auto)
summary(lm_mpg_interaction_1)
#### Segundo ajuste (melhor)
lm_mpg_interaction_2 <- lm(mpg ~ .
- displacement
- acceleration
+ horsepower*weight
+ year:cylinders,
data = subset_Auto)
summary(lm_mpg_interaction_2)
#### Segundo ajuste (melhor)
lm_mpg_interaction_2 <- lm(mpg ~ .
- displacement
- acceleration
+ horsepower:weight
+ year:cylinders,
data = subset_Auto)
summary(lm_mpg_interaction_2)
#### year:cylinders e horsepower:weight aparentam ser estatisticamente relevantes
### f ----
lm_mpg_interaction_3 <- lm(mpg ~ year + horsepower*log(weight), data = subset_Auto)
summary(lm_mpg_interaction_3)
summary(lm_mpg_interaction_1)
#### year:cylinders e horsepower:weight aparentam ser estatisticamente relevantes
### f ----
lm_mpg_interaction_3 <- lm(mpg ~ year + horsepower*(weight^2), data = subset_Auto)
summary(lm_mpg_interaction_3)
#### year:cylinders e horsepower:weight aparentam ser estatisticamente relevantes
### f ----
lm_mpg_interaction_3 <- lm(mpg ~ year + horsepower*sqrt(weight), data = subset_Auto)
summary(lm_mpg_interaction_3)
#### year:cylinders e horsepower:weight aparentam ser estatisticamente relevantes
### f ----
lm_mpg_interaction_3 <- lm(mpg ~ year + log(horsepower)*sqrt(weight), data = subset_Auto)
summary(lm_mpg_interaction_3)
#### year:cylinders e horsepower:weight aparentam ser estatisticamente relevantes
### f ----
lm_mpg_interaction_3 <- lm(mpg ~ .
- displacement
- acceleration
+ horsepower:log(weight )
+ year:log(cylinders),
data = subset_Auto)
summary(lm_mpg_interaction_3)
#### year:cylinders e horsepower:weight aparentam ser estatisticamente relevantes
### f ----
lm_mpg_interaction_3 <- lm(mpg ~ .
- displacement
- acceleration
+ horsepower:log(weight )
data = subset_Auto)
summary(lm_mpg_interaction_3)
#### year:cylinders e horsepower:weight aparentam ser estatisticamente relevantes
### f ----
lm_mpg_interaction_3 <- lm(mpg ~ .
- displacement
- acceleration
+ horsepower:(weight^2 )
data = subset_Auto)
summary(lm_mpg_interaction_3)
lm_mpg_interaction_4 <- lm(mpg ~ log(weight) + horsepower*displacement, data = subset_Auto)
summary(lm_mpg_interaction_1)
#### Algumas interações foram realizadas. Porém, não foi encontrado um ajuste
#### melhor do que a interação 2
## 10 ----
#### limpar ambiente
rm(list = ls())
#### Carregar biblioteca
library(ISLR2)
#### Encontrar a posição da variável qualitativa
colnames(Auto)
#### Encontrar a posição da variável qualitativa
colnames(Carseats)
lm_carseats <- lm(Sales ~ Price + Urban + US, Carseats)
summary(lm_carseats)
?Carseats
